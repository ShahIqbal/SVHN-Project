{
  "cells": [
    {
      "metadata": {
        "_uuid": "2c0a508fac169905c41925cbf40b73c16eb57cce"
      },
      "cell_type": "markdown",
      "source": "Using Dropout in Convolution Neural Networks for the SVHN(Street View House Number) Dataset"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\nimport h5py\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.io import loadmat\nfrom skimage import color\nfrom skimage import io\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import classification_report\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\nfrom keras import regularizers\nfrom sklearn.datasets import fetch_mldata\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression, Perceptron\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import SGD, RMSprop, Adam, Nadam\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras.optimizers import SGD, Adadelta, Adagrad\nfrom keras.constraints import max_norm\nfrom keras.layers import Dense, Dropout, LSTM\nfrom keras.layers import Activation, Flatten, Input, BatchNormalization\nfrom keras.layers import Conv1D, MaxPooling1D \nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "762037a6119738578bd219eb35c119f8db1b5777"
      },
      "cell_type": "code",
      "source": "def load_data(path):\n    \"\"\" Helper function for loading a MAT-File\"\"\"\n    data = loadmat(path)\n    return data['X'], data['y']\n\npath = '../input/svhntrain/train_32x32.mat'\npathTest = '../input/svhntest/test_32x32.mat'\nX_train, y_train = load_data(path)\nX_test, y_test = load_data(pathTest)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f24bf3a922e83520a426867537cfbce7b07af5ca"
      },
      "cell_type": "code",
      "source": "# Transposing the the train and test data\n# by converting it from  \n# (width, height, channels, size) -> (size, width, height, channels)\n\nX_train, y_train = X_train.transpose((3,0,1,2)), y_train[:,0]\nX_test, y_test = X_test.transpose((3,0,1,2)), y_test[:,0]\n\nprint(\"Training Set\", X_train.shape)\nprint('')\n\nprint(\"Test Set\", X_test.shape)\nprint('')\n\n# Calculate the total number of images\nnum_images = X_train.shape[0]\nnum_images2 = X_test.shape[0]\n\nprint(\"Total Number of Train Images\", num_images)\nprint(\"Total Number of Test Images\", num_images2)\n\n#Label from 10 to 0\ny_train[y_train == 10] = 0\ny_test[y_test == 10] = 0\nprint(np.unique(y_train))\n\n#Validation Set\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.13, random_state=7)\n\ntrain_mean = np.mean(X_train, axis=0) #Shape (32,3)\ntrain_std = np.std(X_train, axis=0) #Shape (32,3)\nX_train_norm = (X_train - train_mean) / train_std\nX_train_255 = np.divide(X_train, 255)\nX_train_255 = np.array(X_train_255)\nprint(\"X_train_norm Shape: \", X_train_norm.shape)\nprint(\"X_train_255 Shape: \", X_train_255.shape)\n\n\n\nX_train_norm_array = np.array(X_train_norm)\ny_train_array = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\nX_val_array = np.array(X_val)\ny_val_array = np.array(y_val)\n\nprint(\"Y Train Shape: \", y_train_array.shape)\n\nX_test_255 = np.divide(X_test, 255)\n\ny_train_cnn = to_categorical(y_train_array, 10)\ny_val_cnn = to_categorical(y_val_array, 10)\ny_test_cnn = to_categorical(y_test, 10)\nprint(\"Y Train CNN Shape: \", y_train_cnn.shape)\nprint(\"Y Val CNN Shape: \", y_val_cnn.shape)\nprint(\"Y Test CNN Shape: \", y_test_cnn.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "018c393c2999c762000e218a78353756f7afc257"
      },
      "cell_type": "code",
      "source": "def plot_images(img, labels, nrows, ncols):\n    \"\"\" Plot nrows x ncols images\n    \"\"\"\n    fig, axes = plt.subplots(nrows, ncols)\n    for i, ax in enumerate(axes.flat): \n        if img[i].shape == (32, 32, 3):\n            ax.imshow(img[i])\n        else:\n            ax.imshow(img[i,:,:,0])\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.set_title(labels[i])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6eb1cea63e6ba37e3c9d8a2c03086fe011b75aa5"
      },
      "cell_type": "code",
      "source": "plot_images(X_train, y_train, 1, 5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e2c2b710e2f4332ebcc842952428a6912f6ad728"
      },
      "cell_type": "code",
      "source": "fig, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n\nfig.suptitle('Class Distribution', fontsize=14, fontweight='bold', y=1.05)\n\nax1.hist(y_train, bins=10)\nax1.set_title(\"Training set\")\nax1.set_xlim(1, 10)\n\nax2.hist(y_test, color='g', bins=10)\nax2.set_title(\"Test set\")\n\nfig.tight_layout()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a37137bd335f7c65747ce293fa5eef318405086c"
      },
      "cell_type": "code",
      "source": "def cnn_model_convAndMaxPool(): \n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), strides=1, activation='relu',\n                            input_shape=(32, 32, 3), kernel_constraint=max_norm(3)))\n#     model.add(Dropout(0.90))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n#     model.add(Dropout(0.75))\n#     model.add(Conv2D(128, kernel_size=(5, 5), activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu', strides=1, kernel_constraint=max_norm(3)))\n#     model.add(Dropout(0.75))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n#     model.add(Dropout(0.50))\n#     model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n    model.add(Conv2D(128, (3, 3), activation='relu', strides=1, kernel_constraint=max_norm(3)))\n#     model.add(Dropout(0.50))\n    model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n#     model.add(Dropout(0.50))\n    model.add(Flatten())\n    model.add(Dense(10))\n#     model.add(Activation('relu'))\n#     #model.add(Dropout(0.50))\n#     model.add(Dense(10))\n    model.add(Activation('softmax'))\n#     model.add(Dense(10))\n#     model.add(Activation('softmax'))\n    \n    return model;\n\n\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9bf7c8eeb56957021cc1955cc90fd2a229c55ea2"
      },
      "cell_type": "code",
      "source": "X_test_255.shape, X_train_255.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a0b27392f3fe22007d17125808ac77a5a359a8ef"
      },
      "cell_type": "code",
      "source": "#Accuracy = 0.9319683466502766\ndef cnn_model_convMaxPoolDropoutEveryLayer():\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=3, input_shape=(32,32,3), padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(32, 3, padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.50))\n\n    model.add(Conv2D(64, 3, padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(64, 3, padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.30))\n\n    model.add(Conv2D(128, 3, padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Conv2D(128, 3, padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.30))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.10))\n\n    model.add(Dense(10, activation='softmax'))\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "54787820bc3c6be06445eb22d5aadadd4dd0ec4e",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "batch_size = 128\nnb_classes = 10\nnb_epoch = 20\n# X_train_array = np.array(X_train)\nmodel = cnn_model_convMaxPoolDropoutEveryLayer()\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\n# model.fit(X_train_norm_array, y_train_cnn, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_val_array, y_val_cnn))\nmodel.fit(X_train_255, y_train_cnn, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, validation_data=(X_val_array, y_val_cnn))\n# score = model.evaluate(X_test, y_test_cnn, verbose=0)\nscore = model.evaluate(X_test_255, y_test_cnn, verbose=0)\nprint('loss:', score[0])\nprint('Test accuracy:', score[1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f471f9fa3da8c55427a16ddc15de15257ee5cf95"
      },
      "cell_type": "markdown",
      "source": ""
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}